# MCP (Model Context Protocol) Integration Documentation

## Overview

The MCP (Model Context Protocol) Integration provides a comprehensive system for discovering and interacting with external services using the Model Context Protocol. This includes a dedicated MCP model for optimized configuration and performance for MCP-specific tasks.

## Components

### 1. Dedicated MCP Model

The Dedicated MCP Model is a specialized model designed specifically for handling MCP-related queries. It provides a separate, dedicated instance for processing MCP service requests, allowing for optimized configuration and performance for MCP-specific tasks.

#### Architecture

The Dedicated MCP Model extends the functionality of the original MCPCapableModel but uses separate configuration settings. This separation allows for:

- Different LLM providers/models for MCP-specific tasks
- Specialized system prompts for MCP service interactions
- Optimized configuration for MCP-related queries
- Better resource management and scaling

#### Configuration

The Dedicated MCP Model uses the following environment variables for configuration:

```
# Dedicated MCP LLM Configuration (separate model specifically for MCP-related queries)
DEDICATED_MCP_LLM_PROVIDER=LM Studio
DEDICATED_MCP_LLM_MODEL=qwen2.5-coder-7b-instruct-abliterated@q3_k_m
DEDICATED_MCP_LLM_HOSTNAME=localhost
DEDICATED_MCP_LLM_PORT=1234
DEDICATED_MCP_LLM_API_PATH=/v1
```

#### Fallback Behavior

If the dedicated MCP configuration is not set, the model will fall back to using the general MCP configuration:

```
# MCP LLM Configuration (for MCP service queries)
MCP_LLM_PROVIDER=LM Studio
MCP_LLM_MODEL=qwen2.5-coder-7b-instruct-abliterated@q3_k_m
MCP_LLM_HOSTNAME=localhost
MCP_LLM_PORT=1234
MCP_LLM_API_PATH=/v1
```

And if neither is set, it will fall back to the prompt configuration.

#### Usage in LangGraph Agent

The Dedicated MCP Model is integrated into the LangGraph agent workflow:

1. `query_mcp_services_node` - Uses the dedicated model to generate tool calls for MCP services
2. `execute_mcp_tool_calls_and_return_node` - Uses the dedicated model to execute tool calls
3. `return_mcp_response_to_llm_node` - Uses the dedicated model to format responses for the LLM

#### Key Features

- **Separate Configuration**: Independent settings for optimal MCP service handling
- **Specialized Prompts**: Tailored system prompts for MCP-specific tasks
- **Fallback Support**: Graceful degradation to original MCPCapableModel if dedicated model unavailable
- **Integration**: Seamlessly integrates with existing MCP service discovery and execution workflows

#### Implementation Details

The DedicatedMCPModel class implements the same interface as MCPCapableModel, providing:

- `generate_mcp_tool_calls()` - Generates appropriate tool calls for MCP services
- `execute_mcp_tool_calls()` - Executes the generated tool calls
- `return_response_to_llm()` - Formats responses for LLM processing
- `_call_mcp_service()` - Handles actual communication with MCP services

### 2. MCP Search Server

The MCP Search Server is an MCP-compliant service that enables LLM models to perform web search queries via the Brave Search API. This server follows the same patterns as the existing DNS resolution server, providing a consistent interface for external services.

#### Purpose

The MCP Search Server allows LLM models to perform web searches when they need current information that isn't available in the connected databases. This is particularly useful for:

- Current events and news
- Real-time data and statistics
- General knowledge queries
- Fact checking

#### Architecture

The server follows the same architecture as the DNS server:

- Implements an HTTP server with custom request handlers
- Registers itself with the MCP service registry
- Maintains heartbeats to stay registered
- Provides a clean API for search queries

#### Configuration

The server can be configured with the following command-line parameters:

```
--host HOST           Host to bind to (default: 127.0.0.1)
--port PORT           Port to bind to (default: 8090)
--registry-url REGISTRY_URL
                      Service registry URL (default: http://127.0.0.1:8080)
--service-id SERVICE_ID
                      Service ID for registry (auto-generated by default)
--service-ttl SERVICE_TTL
                      Service TTL in seconds (default: 60)
--log-level {DEBUG,INFO,WARNING,ERROR}
                      Logging level (default: INFO)
```

#### Environment Variables

The server requires the following environment variable to be set:

- `BRAVE_SEARCH_API_KEY`: Your Brave Search API key (available from https://brave.com/search/api/)

#### Usage

##### Starting the Server

```bash
export BRAVE_SEARCH_API_KEY=your_brave_search_api_key
python mcp_search_server.py --host 127.0.0.1 --port 8090 --registry-url http://127.0.0.1:8080
```

##### Making Search Requests

Once the server is running and registered with the MCP service registry, LLM models can make search requests through the MCP framework. The server will:

1. Receive a search query from the MCP framework
2. Call the Brave Search API with the provided query
3. Format the results and return them to the requesting service

#### API Response Format

The server returns search results in the following format:

```json
{
  "success": true,
  "result": {
    "success": true,
    "query": "search query",
    "results": [
      {
        "title": "Result title",
        "url": "https://example.com",
        "description": "Result description",
        "date": "2023-01-01",
        "language": "en",
        "thumbnail": "https://example.com/thumbnail.jpg"
      }
    ],
    "error": null
  }
}
```

#### Integration with MCP Framework

The search server integrates with the MCP framework by:

1. Registering itself with the service registry as type `mcp_search`
2. Advertising its capabilities as a `search_engine` with `web_search` and `brave_search` capabilities
3. Providing a standardized interface for search queries
4. Handling errors gracefully and returning appropriate responses

#### Security Considerations

- The server validates incoming requests and handles errors appropriately
- API keys are loaded from environment variables rather than hardcoded
- The server implements proper request/response handling with error responses

## Best Practices

1. Use a lightweight, fast model for the dedicated MCP model since MCP queries are typically simpler
2. Configure appropriate timeouts for MCP service calls
3. Monitor MCP service availability and response times
4. Consider using a different provider/model than your primary LLM for better resource allocation
5. Secure your MCP service registry and ensure only trusted services can register
6. Regularly rotate API keys for MCP services
7. Implement proper error handling and logging for MCP service interactions