# Database Configuration (for SQL MCP server)
DB_TYPE=postgresql
DB_USERNAME=postgres
DB_PASSWORD=ebe3NM2
DB_HOSTNAME=localhost
DB_PORT=5432
DB_NAME=contacts_db
DATABASE_URL=postgresql://postgres:ebe3NM2@localhost:5432/contacts_db
DEFAULT_DATABASE_ENABLED=true
DATABASE_ENABLED=false
MCP_ENABLED=True
CONFIGURE_MCP_MODELS=false

# Default LLM Model Configuration
DEFAULT_LLM_PROVIDER=LM Studio
DEFAULT_LLM_MODEL=qwen3-4b
DEFAULT_LLM_HOSTNAME=asus-tus
DEFAULT_LLM_PORT=1234
DEFAULT_LLM_API_PATH=/v1

# OpenAI API Key
OPENAI_API_KEY=lm-studio

# DeepSeek API Key
DEEPSEEK_API_KEY=sk-010da76e2839459084108340e21586bb

# GigaChat Configuration
GIGACHAT_CREDENTIALS=MDE5Yjk0YjctMDEzMS03NzI2LTk5ZGYtZGYzNTRhOTlhYWQ3OjQ3ZWRhMDY3LTI1M2MtNDdkZi1hODBiLTQyNzE3YWIwNjk2Mg==
GIGACHAT_SCOPE=GIGACHAT_API_PERS
GIGACHAT_ACCESS_TOKEN=
GIGACHAT_VERIFY_SSL_CERTS=n

# Brave Search API Key
BRAVE_SEARCH_API_KEY=BSAh1LVPlS2vl5hVq4j_yClWvqmKymX

# LLM Model Configuration
SQL_LLM_PROVIDER=LM Studio
SQL_LLM_MODEL=md-coder-qwen3-8b
SQL_LLM_HOSTNAME=asus-tus
SQL_LLM_PORT=1234
SQL_LLM_API_PATH=/v1
RESPONSE_LLM_PROVIDER=LM Studio
RESPONSE_LLM_MODEL=md-coder-qwen3-8b
RESPONSE_LLM_HOSTNAME=asus-tus
RESPONSE_LLM_PORT=1234
RESPONSE_LLM_API_PATH=/v1
PROMPT_LLM_PROVIDER=LM Studio
PROMPT_LLM_MODEL=md-coder-qwen3-8b
PROMPT_LLM_HOSTNAME=asus-tus
PROMPT_LLM_PORT=1234
PROMPT_LLM_API_PATH=/v1

# MCP LLM Configuration (integrated into main LLM section)
MCP_LLM_PROVIDER=LM Studio
MCP_LLM_MODEL=md-coder-qwen3-8b
MCP_LLM_HOSTNAME=asus-tus
MCP_LLM_PORT=1234
MCP_LLM_API_PATH=/v1

# Security Configuration
TERMINATE_ON_POTENTIALLY_HARMFUL_SQL=false

# Security LLM Configuration (for advanced SQL security analysis)
# Whether to use the security LLM for analysis (set to false to use basic keyword matching only)
USE_SECURITY_LLM=False
SECURITY_LLM_PROVIDER=OpenAI
SECURITY_LLM_MODEL=qwen2.5-coder-7b-instruct-abliterated_at_q3_k_m
SECURITY_LLM_HOSTNAME=api.openai.com
SECURITY_LLM_PORT=443
SECURITY_LLM_API_PATH=/v1

# Logging Configuration
ENABLE_SCREEN_LOGGING=True

# MCP Registry Configuration
MCP_REGISTRY_URL=http://127.0.0.1:8080

# RAG Component Configuration
RAG_ENABLED=True
RAG_MODE=mcp  # Options: library, rest, mcp
RAG_REST_ENDPOINT=http://127.0.0.1:5003
EMBEDDING_PROVIDER=lm studio
EMBEDDING_MODEL=text-embedding-bge-m3
EMBEDDING_HOSTNAME=asus-tus
EMBEDDING_PORT=1234
EMBEDDING_API_PATH=/v1
RAG_EMBEDDING_PROVIDER=lm studio
RAG_EMBEDDING_MODEL=text-embedding-bge-m3
RAG_VECTOR_STORE_TYPE=chroma
RAG_TOP_K_RESULTS=5
RAG_SIMILARITY_THRESHOLD=0.7
RAG_CHUNK_SIZE=1000
RAG_CHUNK_OVERLAP=100
RAG_CHROMA_PERSIST_DIR=/root/qwen_test/ai_agent/data/chroma_db
RAG_COLLECTION_NAME=documents
RAG_SUPPORTED_FILE_TYPES=.txt,.pdf,.docx,.html,.md
RAG_PDF_TO_MARKDOWN_CONVERSION_ENABLED=false  # Set to true to enable PDF to Markdown conversion
RAG_USE_FALLBACK_ON_CONVERSION_ERROR=true  # Whether to fall back to PyPDFLoader if conversion fails

# Model Disable Configuration
# Set to 'true' to disable specific model components
DISABLE_PROMPT_GENERATION=True
DISABLE_RESPONSE_GENERATION=False

# Service Enable/Disable Configuration
# Set to 'true' to enable the service, 'false' to disable
SQL_ENABLE=true
WEB_SEARCH_ENABLE=true
DNS_ENABLE=true
DOWNLOAD_ENABLE=true

# Marker LLM Configuration for PDF processing
MARKER_LLM_PROVIDER=openai
OPENAI_BASE_URL=http://asus-tus:1234/v1
OPENAI_MODEL=gemini-2.5-flash
OPENAI_API_KEY=lm-studio

# Force all components to use the default model (overrides individual component settings)
FORCE_DEFAULT_MODEL_FOR_ALL=true

FLASK_ENV=production

