# .env.example - Configuration file with placeholder values
#
# This is an example configuration file. Do not commit actual credentials to version control.
# Copy this file to '.env' and fill in your actual credentials and configuration values.
# Keep the '.env' file in your '.gitignore' to prevent accidental commits of sensitive data.
#

# Database Configuration
DB_TYPE=postgresql
DB_USERNAME=your_username
DB_PASSWORD=your_password
DB_HOSTNAME=localhost
DB_PORT=5432
DB_NAME=your_database_name
DATABASE_URL=postgresql://your_username:your_password@localhost:5432/your_database_name
DEFAULT_DATABASE_ENABLED=true
DATABASE_ENABLED=true
MCP_ENABLED=true
CONFIGURE_MCP_MODELS=false

# Default LLM Model Configuration
DEFAULT_LLM_PROVIDER=LM Studio
DEFAULT_LLM_MODEL=your_model_name
DEFAULT_LLM_HOSTNAME=your_hostname
DEFAULT_LLM_PORT=1234
DEFAULT_LLM_API_PATH=/v1
# Example additional database:
# DB_ANALYTICS_URL=postgresql://username:password@hostname:port/dbname
# DB_ANALYTICS_TYPE=postgresql
# DB_ANALYTICS_USERNAME=username
# DB_ANALYTICS_PASSWORD=password
# DB_ANALYTICS_HOSTNAME=hostname
# DB_ANALYTICS_PORT=5432
# DB_ANALYTICS_NAME=dbname

# OpenAI API Key
OPENAI_API_KEY=your_openai_api_key

# DeepSeek API Key
DEEPSEEK_API_KEY=your_deepseek_api_key

# GigaChat Configuration
GIGACHAT_CREDENTIALS=your_gigachat_credentials
GIGACHAT_SCOPE=GIGACHAT_API_PERS
GIGACHAT_ACCESS_TOKEN=
GIGACHAT_VERIFY_SSL_CERTS=true

# Brave Search API Key
BRAVE_SEARCH_API_KEY=your_brave_search_api_key

# LLM Model Configuration
SQL_LLM_PROVIDER=OpenAI
SQL_LLM_MODEL=your_model_name
SQL_LLM_HOSTNAME=api.openai.com
SQL_LLM_PORT=443
SQL_LLM_API_PATH=/v1
RESPONSE_LLM_PROVIDER=OpenAI
RESPONSE_LLM_MODEL=your_model_name
RESPONSE_LLM_HOSTNAME=api.openai.com
RESPONSE_LLM_PORT=443
RESPONSE_LLM_API_PATH=/v1
PROMPT_LLM_PROVIDER=OpenAI
PROMPT_LLM_MODEL=your_model_name
PROMPT_LLM_HOSTNAME=api.openai.com
PROMPT_LLM_PORT=443
PROMPT_LLM_API_PATH=/v1

# MCP Capable Model Configuration
MCP_SQL_LLM_PROVIDER=OpenAI
MCP_SQL_LLM_MODEL=your_model_name
MCP_SQL_LLM_HOSTNAME=api.openai.com
MCP_SQL_LLM_PORT=443
MCP_SQL_LLM_API_PATH=/v1
MCP_RESPONSE_LLM_PROVIDER=OpenAI
MCP_RESPONSE_LLM_MODEL=your_model_name
MCP_RESPONSE_LLM_HOSTNAME=api.openai.com
MCP_RESPONSE_LLM_PORT=443
MCP_RESPONSE_LLM_API_PATH=/v1
MCP_PROMPT_LLM_PROVIDER=OpenAI
MCP_PROMPT_LLM_MODEL=your_model_name
MCP_PROMPT_LLM_HOSTNAME=api.openai.com
MCP_PROMPT_LLM_PORT=443
MCP_PROMPT_LLM_API_PATH=/v1

# Security Configuration
TERMINATE_ON_POTENTIALLY_HARMFUL_SQL=false

# Security LLM Configuration (for advanced SQL security analysis)
# Whether to use the security LLM for analysis (set to false to use basic keyword matching only)
USE_SECURITY_LLM=true
SECURITY_LLM_PROVIDER=LM Studio
SECURITY_LLM_MODEL=your_model_name
SECURITY_LLM_HOSTNAME=your_hostname
SECURITY_LLM_PORT=1234
SECURITY_LLM_API_PATH=/v1

# Dedicated MCP Model Configuration (separate model specifically for MCP-related queries)
DEDICATED_MCP_LLM_PROVIDER=LM Studio
DEDICATED_MCP_LLM_MODEL=your_model_name
DEDICATED_MCP_LLM_HOSTNAME=localhost
DEDICATED_MCP_LLM_PORT=1234
DEDICATED_MCP_LLM_API_PATH=/v1

# Logging Configuration
ENABLE_SCREEN_LOGGING=false

# Model Disable Configuration
# Set to 'true' to disable specific model components
DISABLE_PROMPT_GENERATION=false
DISABLE_RESPONSE_GENERATION=false

# MCP Registry Configuration
MCP_REGISTRY_URL=http://127.0.0.1:8080

# RAG Component Configuration
RAG_ENABLED=true
RAG_EMBEDDING_MODEL=all-MiniLM-L6-v2
RAG_VECTOR_STORE_TYPE=chroma
RAG_TOP_K_RESULTS=5
RAG_SIMILARITY_THRESHOLD=0.7
RAG_CHUNK_SIZE=1000
RAG_CHUNK_OVERLAP=100
RAG_CHROMA_PERSIST_DIR=./data/chroma_db
RAG_COLLECTION_NAME=documents
RAG_SUPPORTED_FILE_TYPES=.txt,.pdf,.docx,.html,.md

# Flask Environment Configuration
# Set to 'production' to use Gunicorn as the WSGI server, otherwise uses Flask's development server
FLASK_ENV=development